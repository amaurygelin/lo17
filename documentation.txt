ls | wc -l 
    //to know the number of files in the folder OLD - 326
    //that will be our number of documents cause 1 doc = 1 article = 1 file

egrep '<span class="style95" style="color:inherit">[0-9]+' * | wc -l //326 OK
egrep '<span class="style32">BE France [0-9]+' * | wc -l //326 OK
egrep '<p class="style96"><span class="style42">.*<br><\/span>' * | wc -l //326 OK
egrep '<span class="style42">.*[0-9]+\/[0-9]+\/[0-9]+' * | wc -l //326 OK
egrep '<span class="style17">.*<\/span>' * | wc -l //326 OK
egrep '<p class="style96"><span class="style95">.*<\/span>' * | wc -l //18 KO
    (was solved by handling multi lines texts)
egrep '<div style="text-align: center"><img src=".*\.\w{3,4}' * | wc -l //154 OK 
    (some documents don't have any images)
egrep '<span class="style21"><strong>.*<\/strong>' * | wc -l //134 
    (20 images don't have a legend)

./prep_corpus > corpus_temp.xml
./convert.pl corpus_temp.xml > corpus_converted.xml 
    (to remove the HTML special characters of the output)

./segmente_TT.pl corpus_P17_ss_balise.xml > tokens.txt 
    (create tokens using the corpus of the prof)
./segmente_TT.pl -f corpus_P17_ss_balise.xml > tokensFiles.txt 
    (create token/file pairs)

./tf.pl > tf.txt
    (tokensFiles.txt needs to be created)
./df.pl > df.txt
    (tf.txt needs to be created before)
./df_perc.pl > df_perc.txt
    (df.txt needs to be created before)
./idf.pl > idf.txt 
    (df.txt needs to be created before)
./tfidf.pl > tfidf.txt 
    (tf.txt & idf.txt need to be created before)
./stop_list.pl > stop_list.txt 
    (df_perc.txt needs to be created before)
./newcreeFiltre.pl stop_list.txt > remove_stop_words.pl 
    (prints a perl script on a new pl file)
./remove_stop_words.pl corpus_P17_ss_balise.xml > corpus_without_stop_words.xml

./segmente_TT.pl corpus_without_swords.xml > tokens_without_swords.txt 
    (we retokenize the XML without stop words)
    (KO)
    FIXME: tokenization fails on many words (ex °alors etc...), this is probably due to the              replacement in the XML
sort -u tokens_without_swords.txt > words_without_swords.txt
    (we remove duplications with the option -u of sort)
    (OK)

./successeurs_P16.pl words_without_swords.txt > successors.txt
    (OK mais à faire sur un words_without_swords.txt non bugué)
./filtronc_P16.pl -v successors.txt > stemming.txt